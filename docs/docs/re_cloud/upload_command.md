---
sidebar_position: 2
---

# Uploading reports

**re_cloud** library has one command for uploading all the reports: `re_cloud upload`

You can upload 4 currently supported reports with this command. Here the list of how to do it: ðŸ˜Š

## commands

### dbt-docs

```
re_cloud upload dbt-docs --name TEXT --project-dir TEXT

Options:
  --project-dir TEXT  Which directory to look in for the dbt_project.yml file.
                      Default is the current working directory and its parents
  --name TEXT         Name of the upload used for identification
```

### pandas-profiling

```
re_cloud upload pandas-profiling --name TEXT  --report-file TEXT

Options:
--report-file TEXT  Pandas profiling file with html report  [required]
--name TEXT         Name of the upload used for identification
```

### great-expectations

```
re_cloud upload great-expectations --name TEXT

Options:
  --name TEXT  Name of the upload used for identification
```

### re-data

```
re_cloud upload re-data --name TEXT --project-dir TEXT --re-data-target-dir TEXT

Options:
  --project-dir TEXT         Which directory to look in for the
                             dbt_project.yml file. Default is the current
                             working directory and its parents

  --re-data-target-dir TEXT  Which directory to store artefacts generated by
                             re_data Defaults to the 'target-path' used in
                             dbt_project.yml

  --name TEXT                Name of the upload used for identification
```

## common parameters

### `name`

Name which you would like to give to the report, this will show in the interface. Names don't need to and often will not be unique, given that in most of the pipelines you will be uploading similar reports every day / hours, etc.